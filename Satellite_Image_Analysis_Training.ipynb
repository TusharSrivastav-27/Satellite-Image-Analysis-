{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Satellite_Image_Analysis.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1x2xBFzdf2dz6yiSIMNuHGlNBSFVBNPP_","authorship_tag":"ABX9TyMLfjvDO2SZzigfKvpyU1xD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Hm3C_LKh1ViK"},"source":["from keras.applications import vgg16\n","img_rows, img_cols = 32, 32\n","VGG=vgg16.VGG16(weights='imagenet',include_top=False ,input_shape=(img_rows, img_cols,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_FO9psY1vXv"},"source":["for layer in VGG.layers:\n","    layer.trainable=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1m5Lpf9A1yYt"},"source":["def top(bottom_model, num_classes):\n","\n","    top_model = bottom_model.output\n","    top_model = GlobalAveragePooling2D()(top_model)\n","    top_model = Dense(1024,activation='relu')(top_model)\n","    top_model = Dense(512,activation='relu')(top_model)\n","    top_model = Dense(512,activation='relu')(top_model)\n","    top_model = Dense(256,activation='relu')(top_model)\n","    top_model = Dense(128,activation='relu')(top_model)\n","    top_model = Dense(num_classes,activation='softmax')(top_model)\n","    return top_model "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sUGBGvRc1168","executionInfo":{"status":"ok","timestamp":1639724225583,"user_tz":-330,"elapsed":455,"user":{"displayName":"Tushar Srivastav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRcQxjTorO3iDT3Jau4fX7EssAaxZjt1sYND1K=s64","userId":"07222400350070830397"}},"outputId":"396f9d03-c430-41c1-9c0d-afb8eb4b415f"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n","from keras.layers.normalization import batch_normalization\n","from tensorflow.keras.models import Model\n","\n","num_classes = 3\n","\n","FC_Head = top(VGG, num_classes)\n","\n","model = Model(inputs = VGG.input, outputs = FC_Head)\n","\n","print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n"," global_average_pooling2d_1   (None, 512)              0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dense_6 (Dense)             (None, 1024)              525312    \n","                                                                 \n"," dense_7 (Dense)             (None, 512)               524800    \n","                                                                 \n"," dense_8 (Dense)             (None, 512)               262656    \n","                                                                 \n"," dense_9 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_10 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dense_11 (Dense)            (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 16,192,067\n","Trainable params: 1,477,379\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxvVMykF152m","executionInfo":{"status":"ok","timestamp":1639724230903,"user_tz":-330,"elapsed":653,"user":{"displayName":"Tushar Srivastav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRcQxjTorO3iDT3Jau4fX7EssAaxZjt1sYND1K=s64","userId":"07222400350070830397"}},"outputId":"6d69a690-a43d-46d2-8dab-b2829c1417a5"},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_data_dir = '/content/drive/MyDrive/MiniProject_Satellite/Data Set Sattelite/Train'\n","validation_data_dir = '/content/drive/MyDrive/MiniProject_Satellite/Data Set Sattelite/Validation'\n"," \n","train_datagen = ImageDataGenerator(rescale=1./255)\n"," \n","validation_datagen = ImageDataGenerator(rescale=1./255)\n"," \n","batch_size = 32\n"," \n","train_generator = train_datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=(img_rows, img_cols),\n","        batch_size=batch_size,\n","        class_mode='categorical')\n"," \n","validation_generator = validation_datagen.flow_from_directory(\n","        validation_data_dir,\n","        target_size=(img_rows, img_cols),\n","        batch_size=batch_size,\n","        class_mode='categorical')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 7029 images belonging to 3 classes.\n","Found 1500 images belonging to 3 classes.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQghBlYu2Bad","executionInfo":{"status":"ok","timestamp":1639726227494,"user_tz":-330,"elapsed":1990627,"user":{"displayName":"Tushar Srivastav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRcQxjTorO3iDT3Jau4fX7EssAaxZjt1sYND1K=s64","userId":"07222400350070830397"}},"outputId":"51a4e620-1900-4c5f-8bf7-38f4149f93c5"},"source":["from keras.optimizers import rmsprop_v2\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","                  \n","checkpoint = ModelCheckpoint(\"satellite2_vgg.h5\",\n","                             monitor=\"val_loss\",\n","                             mode=\"min\",\n","                             save_best_only = True,\n","                             verbose=1)\n","\n","earlystop = EarlyStopping(monitor = 'val_loss', \n","                          min_delta = 0, \n","                          patience = 3,\n","                          verbose = 1,\n","                          restore_best_weights = True)\n","\n","callbacks = [earlystop, checkpoint]\n"," \n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = rmsprop_v2.RMSprop(learning_rate=0.001),\n","              metrics = ['accuracy'])\n","\n","nb_train_samples = 7029\n","nb_validation_samples = 1500\n"," \n","epochs = 10\n","batch_size = 32\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch = nb_train_samples // batch_size,\n","    epochs = epochs,\n","    callbacks = callbacks,\n","    validation_data = validation_generator,\n","    validation_steps = nb_validation_samples // batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","219/219 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.9315\n","Epoch 00001: val_loss improved from inf to 0.11101, saving model to satellite2_vgg.h5\n","219/219 [==============================] - 1863s 9s/step - loss: 0.1977 - accuracy: 0.9315 - val_loss: 0.1110 - val_accuracy: 0.9620\n","Epoch 2/10\n","219/219 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9708\n","Epoch 00002: val_loss improved from 0.11101 to 0.07080, saving model to satellite2_vgg.h5\n","219/219 [==============================] - 20s 92ms/step - loss: 0.0994 - accuracy: 0.9708 - val_loss: 0.0708 - val_accuracy: 0.9837\n","Epoch 3/10\n","219/219 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9771\n","Epoch 00003: val_loss improved from 0.07080 to 0.06067, saving model to satellite2_vgg.h5\n","219/219 [==============================] - 20s 92ms/step - loss: 0.0843 - accuracy: 0.9771 - val_loss: 0.0607 - val_accuracy: 0.9789\n","Epoch 4/10\n","219/219 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9766\n","Epoch 00004: val_loss improved from 0.06067 to 0.05311, saving model to satellite2_vgg.h5\n","219/219 [==============================] - 20s 91ms/step - loss: 0.0806 - accuracy: 0.9766 - val_loss: 0.0531 - val_accuracy: 0.9789\n","Epoch 5/10\n","219/219 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9776\n","Epoch 00005: val_loss did not improve from 0.05311\n","219/219 [==============================] - 19s 89ms/step - loss: 0.0715 - accuracy: 0.9776 - val_loss: 0.0584 - val_accuracy: 0.9803\n","Epoch 6/10\n","219/219 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9797\n","Epoch 00006: val_loss did not improve from 0.05311\n","219/219 [==============================] - 19s 89ms/step - loss: 0.0835 - accuracy: 0.9797 - val_loss: 0.0790 - val_accuracy: 0.9769\n","Epoch 7/10\n","219/219 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9821Restoring model weights from the end of the best epoch: 4.\n","\n","Epoch 00007: val_loss did not improve from 0.05311\n","219/219 [==============================] - 20s 90ms/step - loss: 0.0635 - accuracy: 0.9821 - val_loss: 0.1378 - val_accuracy: 0.9654\n","Epoch 00007: early stopping\n"]}]}]}